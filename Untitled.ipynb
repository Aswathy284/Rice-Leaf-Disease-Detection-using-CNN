{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b9ab00-586d-4681-b867-cd7c14424850",
   "metadata": {},
   "source": [
    "# PRCP- 1001- RiceLeaf disease detection\r\n",
    "\r\n",
    "Problem Statement\r\n",
    "\r\n",
    "Task 1:-Prepare a complete data analysis report on the given data.\r\n",
    "\r\n",
    "Task 2:-Create a model which can classify the three major attacking diseases of rice plants like leaf blast, bacterial blight and brown spot.\r\n",
    "\r\n",
    "Task3:- Analyze various techniques like Data Augmentation, etc and create a report on that.\r\n",
    "\r\n",
    "\r\n",
    "Dataset Link:\r\n",
    "This dataset contains 120 jpg images of disease-infected rice leaves. The images are grouped into 3 classes based on the type of disease. There are 40 images in each class.\r\n",
    "Classes\r\n",
    "●\tLeaf smut\r\n",
    "●\tBrown spot\r\n",
    "●\tBacterial leaf blight\r\n",
    "Domain: \r\n",
    "\r\n",
    "Link : https://d3ilbtxij3aepc.cloudfront.net/projects/CDS-Capstone-Projects/PRCPceLeaf.zip\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Model Comparison Report\r\n",
    "\r\n",
    "Create a report stating the performance of multiple models on this data and suggest the best model for production.\r\n",
    "\r\n",
    "Report on Challenges faced\r\n",
    "\r\n",
    "Create a report which should include challenges you faced on data and what technique used with proper reason.\r\n",
    "\r\n",
    "\r\n",
    "Note:-All above tasks have to be done on a single jupyter notebook and share the samefor final submission of the project.\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945bf03e-0115-481d-8a9a-f5969ae3ff95",
   "metadata": {},
   "source": [
    "## PYTHON IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525f69c-e3d6-47e2-9dc8-dc65a497012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267bcdc0-fdcb-4e87-bee6-bd91315e2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855c526-1b2f-44e8-b9a2-8c39cf98ff77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3be0a-8893-46b0-b842-bdad995925dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "!wget https://d3ilbtxij3aepc.cloudfront.net/projects/CDS-Capstone-Projects/PRCP-1001-RiceLeaf.zip\n",
    "with zipfile.ZipFile(\"PRCP-1001-RiceLeaf.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"RiceLeafDataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d965822-9651-4175-97fc-af1d29a64905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Paths\n",
    "base_dir = \"RiceLeafDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff79ad-2955-403a-bfc5-fd2b49a1aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "categories = [\"Leaf smut\", \"Brown spot\", \"Bacterial leaf blight\"]\n",
    "category_paths = [os.path.join(base_dir, cat) for cat in categories]\n",
    "\n",
    "for category, path in zip(categories, category_paths):\n",
    "    print(f\"Category: {category}, Number of Images: {len(os.listdir(path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f189be3-9839-409d-9513-6f9bb4c65d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def plot_samples(category_paths, categories):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, path in enumerate(category_paths):\n",
    "        img_path = os.path.join(path, os.listdir(path)[0])\n",
    "        img = plt.imread(img_path)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(categories[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(category_paths, categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06440773-aff5-464a-80bc-81c33f0ed03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "img_size = (128, 128)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf85e5-bfd1-4169-bc26-9ad340f1badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generators\n",
    "data_gen = ImageDataGenerator(rescale=1.0/255,\n",
    "                               validation_split=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               zoom_range=0.2)\n",
    "\n",
    "train_gen = data_gen.flow_from_directory(base_dir,\n",
    "                                         target_size=img_size,\n",
    "                                         batch_size=batch_size,\n",
    "                                         class_mode='categorical',\n",
    "                                         subset='training')\n",
    "\n",
    "val_gen = data_gen.flow_from_directory(base_dir,\n",
    "                                       target_size=img_size,\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode='categorical',\n",
    "                                       subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b09382-858f-4f22-93dc-34cc4cc07971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b732279-49d2-4926-981d-7077d2531466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "epochs = 20\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e8052-e1ab-4c3c-8ccd-d54186968585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4573f8-9a6b-4120-98d2-a09db537259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "val_preds = model.predict(val_gen)\n",
    "y_pred = np.argmax(val_preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=categories))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc786a46-0483-4142-9f5b-727aa2a8e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save(\"rice_leaf_disease_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc0cda-d364-4e8d-ade9-67c3ef942ece",
   "metadata": {},
   "source": [
    "\n",
    "## Challenges and Improvements\n",
    "## - Small dataset size: Used data augmentation.\n",
    "## - Class imbalance: Ensure balanced class distribution.\n",
    "## - Limited computing power: Used a simple CNN architecture instead of a heavy pretrained model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd401c-0eff-486d-b9f1-2d364ba91433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7372c2-396d-49f8-9c48-cd1a1c218b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_folder = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if os.path.exists(input_folder):\n",
    "    print(\"Path exists:\", input_folder)\n",
    "    print(\"Contents:\", os.listdir(input_folder))\n",
    "else:\n",
    "    print(\"Path does not exist. Check the folder path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406523d0-5584-4e08-bf0d-c1df6104eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b094ed3-33d6-47cc-aef4-fd5239e08c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "output_folder = \"/content/drive/MyDrive/Documents/CDS PROJECT/RICE_LEAF_SPLIT/\"  # Or a valid path for local\n",
    "\n",
    "# Perform the split\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=1337, ratio=(0.8, 0.1, 0.1))\n",
    "\n",
    "print(\"Dataset split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf6caf-924d-4ae0-ba43-eb6a18dac99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\\train\"\n",
    "validation_dir = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\\validation\"\n",
    "test_dir = r\"C:\\Users\\Admin\\Documents/CDS PROJECT\\RICE_LEAF\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cf7bf-9849-4a38-b2c0-7a72d3d3e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define paths to training and validation directories\n",
    "train_dir = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\\train\"  # Replace with the actual path\n",
    "validation_dir = r\"C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\\validation\"  # Replace with the actual path\n",
    "\n",
    "# Create train and validation generators\n",
    "batch_size = 16\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(180, 180),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(180, 180),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Calculate the number of steps per epoch\n",
    "train_steps_per_epoch = train_generator.samples // batch_size\n",
    "val_steps_per_epoch = val_generator.samples // batch_size\n",
    "\n",
    "print(f\"Training steps per epoch: {train_steps_per_epoch}\")\n",
    "print(f\"Validation steps per epoch: {val_steps_per_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885729db-bf36-495a-b5d7-43e32cd3dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting train images with their labels\n",
    "def plots(ims, figsize=(20,25), rows=4, interp = False, title = None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims) // rows if len(ims) % 2 ==0 else len(ims) // rows+1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('off')\n",
    "        sp.set_title(class_names[title[i].tolist().index(1)],fontsize=16)\n",
    "        plt.imshow(ims[i])\n",
    "\n",
    "\n",
    "# Make list of classes\n",
    "class_names = ['Bacterial leaf blight', 'Brown spot', 'Leaf smut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4242d5e-2bee-48e1-8159-8f4d798feb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgs, labels = next(train_generator)\n",
    "plots(imgs, title=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bab84-83c6-44e7-a6ca-af6581c866e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the layers\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(180,180,3)))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Add dropout to prevent overfitting\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add the output layer with softmax activation (for multi-class classification)\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Print model summary to check the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555c424-dd8d-4e40-b50c-82b70bc6bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31278e15-4840-4428-ac6c-077e4e8bd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3de7a-46f2-47a5-9831-cb68f37e7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991629c-963e-40bd-893d-29c0cf34674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f60ae2-ee83-4db2-9b9f-358e2fa7f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,  # Number of epochs to train the model\n",
    "    validation_data=val_generator,  # Validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a72b6-b2f8-45d9-ab8f-d6a11a547d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141ea29-dc5a-456a-9f08-2c3efa50fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step:9 Plotting the training accuracy and validation accuracy\n",
    "# Plotting the traning loss and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"r\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629ef32-dd6a-4f53-8c21-c0daac79ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fb060-2c40-4f58-9df9-3e1ec228d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = r'C:\\Users\\Admin\\Documents\\CDS PROJECT\\RICE_LEAF\\test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(180, 180),\n",
    "    batch_size=16,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b059e42-2906-4a6b-9156-4b1097b13cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b5d2e-4807-4da5-a11a-ace7e8dc58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the prediction of the model\n",
    "imgs, labels = next(test_generator)\n",
    "fig =plt.figure(figsize=(15,15))\n",
    "columns = 3\n",
    "rows = 3\n",
    "for i in range(columns*rows):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img_t = np.expand_dims(imgs[i],axis=0)\n",
    "    prediction = model.predict(img_t)\n",
    "    idx = prediction[0].tolist().index(max(prediction[0]))\n",
    "    plt.text(20,58, class_names[idx],color='red',fontsize=10,bbox=dict(facecolor='white',alpha=0.8))\n",
    "    plt.imshow(imgs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
